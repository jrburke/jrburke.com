<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

    <title><![CDATA[James Burke -- javascript]]></title>
    <link href="https://jrburke.com/tags/javascript//atom.xml" rel="self"/>
    <link href="https://jrburke.com/tags/javascript/"/>
    <updated>2016-01-20T06:26:35.443Z</updated>
    <id>https://jrburke.com/tags/javascript/</id>
    <author>
    <name><![CDATA[James Burke]]></name>
    </author>

    <entry>
        <title type="html"><![CDATA[Template strings, components, models and events]]></title>
        <link href="https://jrburke.com/2016/01/19/template-strings-components-models-and-events/"/>
        <updated>2016-01-20T06:26:35.443Z</updated>
        <id>https://jrburke.com/2016/01/19/template-strings-components-models-and-events/</id>
        <content type="html"><![CDATA[<p><em>This is a shorter, rougher post to outline a recent experiment around UI construction. It is a bit high level, and sets some context around the <a href="https://github.com/jrburke/htemplate">htemplate</a> module</em>.</p>

<p>Some nice things about the <a href="https://facebook.github.io/react/">React</a>-related world that I wanted to try for a work project:</p>

<ol>
<li>A component system.</li>
<li>Grouping the DOM building with the JS code that knows about the state (In React, this is the render method, using <code>React.createElement</code> or <a href="https://facebook.github.io/react/docs/displaying-data.html#jsx-syntax">JSX</a>).</li>
<li>From Flux, enforcing visual updates to be triggered from model changes, not from other visual components.</li>
</ol>

<p>However, because of cultural constraints and an interest to keep the up front cost small, keep the stack small and shallow, I wanted to avoid a virtual DOM implementation and a transpiler.</p>

<p>What I ended up using:</p>

<ol>
<li><p><a href="https://developer.mozilla.org/en-US/docs/Web/Web_Components/Custom_Elements">Custom elements</a>. This makes sense for the work project since we want to test out the custom element API, help find bugs. Custom elements are enabled by default for the project, so no special shims or adapters are necessary.</p></li>
<li><p><a href="https://github.com/jrburke/htemplate">htemplate</a>: uses <a href="https://developer.mozilla.org/en/docs/Web/JavaScript/Reference/template_strings#Tagged_template_strings">tagged template strings</a> to allow grouping the state logic in JS with building up the DOM. I get to use ES2015 without needing any build transforms to translate it to ES5, and I wanted to avoid the JSX transforms.</p></li>
<li><p>Adopt a cultural practice of calling the model API, then wait for the model object to update and bind the re-rendering of the custom element to events emitted from the model. The custom elements directly subscribe to the model to get changes instead of passing state down through components via a top level component.</p></li>
</ol>

<p>In order to not take the cost of re-rending stuff that has not changed, the UI would be broken down into smaller custom elements that listened for fine-grained model updates.</p>

<p>This is possible because we have a front end object, called <code>model</code> which sits in front of the core backend model API, and if we notice that we need to group or constraint model update events to help scope visual updates, we have a place to do that.</p>

<p>A similar idea is behind <a href="https://github.com/facebook/graphql">GraphQL</a> and <a href="https://github.com/Netflix/falcor">Falcor</a>, but this approach was done without a formal query language: construct a way to only see part of the whole model, scope data update events to subsets. Model properties/event names were used as the scoping mechanism.</p>

<h2 id="customelementconstruction">Custom element construction</h2>

<p>This can be done in any number of ways, but I was already using <a href="https://github.com/jrburke/element"><code>element</code></a>, so I just continued with it. However, I did not need to use the <a href="https://github.com/jrburke/element#template-loader-plugin-custom-features"><code>template</code></a> module, instead <a href="https://github.com/jrburke/htemplate"><code>htemplate</code></a> was used to construct the DOM within the components.</p>

<p><code>element</code> supports building up the custom element prototype via mixins instead of inheritance, and if multiple mixins define methods for the <a href="https://github.com/jrburke/element#element-lifecycle-background">custom element lifecycle</a>, <code>element</code> will chain them together.</p>

<h2 id="modelconstruction">Model construction</h2>

<p><code>model</code> is an object that mixes in an event emitter. There are lots of choices for event emitters. I used <a href="https://github.com/jrburke/evt"><code>evt</code></a> because it supports a <code>.latest()</code> concept, where it will call the listener if there is a current value for the event property, and for any future updates.</p>

<h2 id="bindingthemodeltotheview">Binding the model to the view</h2>

<p><code>element</code> mixins are used to bind the model updates to a <code>render()</code> method on the component. A sample of the end result:</p>

<ul>
<li><code>base_render</code> sets up the relationship between htemplate and the model.</li>
<li><code>['accounts', 'folders']</code> are the model properties that this component wants to get updates about.</li>
<li>The function is the "renderFn" given to <code>htemplate</code>.</li>
<li>The html`` part is the tagged template string created by htemplate.</li>
<li>The model object is passed to the custom element as <code>this.model</code>.</li>
</ul>

<pre><code class="language-javascript">{
  render: require('../base_render')(['accounts', 'folders'], function(html) {
    var currentAccount = this.model.account;
    if (!currentAccount) {
      return;
    }

    html`
    &lt;a data-prop="accountHeader"
       data-dclick="toggleAccounts"
       class="fld-acct-header closed" role="region"&gt;
      &lt;span class="fld-acct-header-account-label"&gt;${currentAccount.name}&lt;/span&gt;
      &lt;span class="fld-acct-header-account-header"
            data-l10n-id="drawer-accounts-header"&gt;&lt;/span&gt;
      &lt;span class="fld-account-switch-arrow"&gt;&lt;/span&gt;
    &lt;/a&gt;
    &lt;div data-prop="fldAcctScrollInner" class="fld-acct-scrollinner"&gt;
      &lt;div data-prop="fldAcctContainer" class="fld-acct-container"&gt;
        &lt;!-- The list of accounts --&gt;
        &lt;div data-prop="accountContainer"
             data-dclick="onClickAccount"
             class="fld-accountlist-container collapsed"&gt;
        `;

        // Add DOM for each account.
        if (this.state.accounts) {
          this.state.accounts.items.forEach((account) =&gt; {
            // Highlight the account currently in use
            var selectedClass = this.model.account &amp;&amp;
                                this.model.account.id === account.id ?
                                'fld-account-selected' : '';

            html`
            &lt;a class="fld-account-item ${selectedClass}"
               data-account-id="${account.id}"&gt;
              &lt;span class="selected-indicator"&gt;&lt;/span&gt;
              &lt;span class="fld-account-name"&gt;${account.name}&lt;/span&gt;
            &lt;/a&gt;
            `;
          });
        }

        html`
        &lt;/div&gt;
        &lt;!-- The list of folders for the current account. --&gt;
        &lt;div data-prop="foldersContainer"
             data-dclick="onClickFolder"
             class="fld-folders-container"&gt;
        `;

          if (this.state.folders) {
            this.state.folders.items.forEach((folder) =&gt; {
              var extraClasses = [];

              if (!folder.selectable) {
                extraClasses.push('fld-folder-unselectable');
              }

              var depthIdx = Math.min(FOLDER_DEPTH_CLASSES.length - 1,
                                      folder.depth);
              extraClasses.push(FOLDER_DEPTH_CLASSES[depthIdx]);
              if (depthIdx &gt; 0) {
                extraClasses.push('fld-folder-depthnonzero');
              }

              if (folder === this.model.folder) {
                extraClasses.push('fld-folder-selected');
              }

              html`
              &lt;a class="fld-folder-item ${extraClasses.join(' ')}"
                 data-type="${folder.type}"
                 data-folder-id="${folder.id}"&gt;
                &lt;span class="selected-indicator"&gt;&lt;/span&gt;
                &lt;span dir="auto"
                      class="fld-folder-name"&gt;${folder.name}&lt;/span&gt;
                &lt;span class="fld-folder-unread"&gt;&lt;/span&gt;
              &lt;/a&gt;
              `;
            });
          }

        html`
        &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    `;
  })
}
</code></pre>

<p>If the accounts or folders update frequently, then I could create smaller custom elements that focus on displaying those pieces based on the individual model property changes. However, for the time that this UI is shown, those model properties will rarely change, so inlining the work to show both lists in one component is fine.</p>

<h2 id="htemplatenotes">htemplate notes</h2>

<p>htemplate supports passing non-string values to sub-elements by setting a property on the sub-element instead of setting a string attribute. This is useful to pass down objects, like the <code>model</code> object, to sub-elements. More details in the <a href="#https://github.com/jrburke/htemplate#property-setting">Property setting section of the htemplate readme</a>.</p>

<p>Editor support for syntax highlighting HTML inside the tagged template strings helps with the string legibility. It would be great to get more editors supporting it as I expect it will become  more common as tagged template strings get more visibility. Here are a couple of issues tracking that for different editors:</p>

<ul>
<li><a href="https://github.com/atom/language-javascript/pull/282">Atom editor</a></li>
<li><a href="https://github.com/Benvie/JavaScriptNext.tmLanguage/issues/134">Sublime Text, JavaScriptNext.tmLanguage package</a></li>
</ul>

<p>If you can, help your editor improve the display of a HTML string templates.</p>

<h2 id="summary">Summary</h2>

<p>I like the feel of it so far. As with most technology choices, it is about the tradeoffs you can accept.</p>

<p>I am fortunate to be able to use ES2015 and custom elements natively, not an option for many projects. It is fun to play in the future natively, I am excited to see those pieces become widely available across browsers.</p>

<p>Not using a virtual DOM implementation requires more thought on rate of updates for a component. Instead of just letting a React render pass sort out the details, The rate of model update events should be considered more, and possibly creating smaller components that care about finer grained model updates.</p>

<p>A virtual DOM can allow the developer to be more carefree about this, at the possible cost of React creating a larger set of internal objects to do a diff when the model changes only affect a small portion of the UI.</p>

<p>There are some cases where I do not want to just blast the innerHTML of the custom element on every model update. For instance, a CSS animated spinner that is activated by a class change to an element. In that case, I do not want to reset the innerHTML as the animating spinner would appear to jump around and reset. In those cases the custom element may decide to check if the existing DOM has the class set correctly instead of always resetting the innerHTML. A more manual diff model.</p>

<p>On the flip side, those cases are small and scoped, and the overall bootstrap code size of the project is smaller, with less build machinery in place.</p>

<p>So, tradeoffs. To be clear, the React ecosystem has a lot to offer, but it has been fun exploring an alternate approach inspired by some aspects of it but with different tradeoffs.</p>]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[amodro-trace and AMD loaders]]></title>
        <link href="https://jrburke.com/2015/04/09/amodro-trace-and-amd-loaders/"/>
        <updated>2015-04-09T20:26:35.414Z</updated>
        <id>https://jrburke.com/2015/04/09/amodro-trace-and-amd-loaders/</id>
        <content type="html"><![CDATA[<p>A new tool, and some AMD loader rambling:</p>

<p>I have started a new project around AMD modules, <a href="https://github.com/amodrojs/amodro-trace">amodro-trace</a>. It is a tool that understands AMD modules and is meant to be used in other node-based build systems. The README has more background, but the general use cases that drove it:</p>

<ul>
<li>Get a dependency tree for a module ID</li>
<li>Allows non-file inputs</li>
<li>Allows transpiling inputs to AMD before tracing</li>
<li>Allows content transforms after AMD normalization</li>
</ul>

<p>Think of amodro-trace as a lower level imperative tool that something like the requirejs optimizer could use to implement its declarative API.</p>

<p>amodro-trace comes from some code in the requirejs optimizer, and has some smaller unit tests. I ran it over a larger project, but still expect to fine tune some things around API and operation, so feel free to give feedback in the issues list if the use cases fit your needs but have trouble using it.</p>

<p>I would also like to construct a new AMD loader, something that assumes more modern browsers and can improve on some things learned from requirejs.</p>

<p>I do not expect requirejs to go away any time soon, and it will still be my recommendation for general AMD loading across a wide set of browsers. There will still be maintenance releases, but I expect to do any new work that non-trivially modifies behavior to be done under a new name. This helps set stable expectations, particularly for tools that have been built on top of requirejs.</p>

<p>I still want to explore some things with AMD loaders though, particularly since an <a href="http://jrburke.com/2015/02/13/how-to-know-when-es-modules-are-done/">operational ES module system is still far off</a>, and transpilers that guess at ES module syntax still benefit from good AMD loader options to back them.</p>

<h2 id="amdloaderoptions">AMD loader options</h2>

<p>First, a bit about some AMD loader options that I have worked on. The nice thing about AMD modules is that there are more options besides this set, and other tooling around them. This is just about where and how I have spent my time in this space.</p>

<ul>
<li><a href="http://requirejs.org/">requirejs</a>: the baseline loader. Along with its <a href="http://requirejs.org/docs/optimization.html">optimizer</a>, it has a fairly large set of tests and stability. (Side note: the code that would become requirejs started in 2009, first releases in 2010, with some ideas stretching back much earlier from Dojo.)</li>
<li><a href="https://github.com/requirejs/cajon">cajon</a>: Built around requirejs, but bundles an XHR fetch option to allow for consuming CommonJS modules directly as well as AMD modules. Comes with the caveats of using an XHR loader though, like <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Access_control_CORS">CORS</a> and <a href="https://developer.mozilla.org/en-US/docs/Web/Security/CSP/Introducing_Content_Security_Policy">CSP</a> issues.</li>
<li><a href="https://github.com/requirejs/alameda">alameda</a>: Like requirejs, but assumes more modern browsers as a baseline (mainly means does not support IE9 and below), uses promises under the hood. There is a <a href="https://github.com/requirejs/alameda/tree/native-promise">native-promise</a> branch that does not use a promise shim, just native browser promises. alameda is used by some <a href="https://github.com/mozilla-b2g/gaia">Gaia</a> apps that use modules.</li>
<li><a href="https://github.com/jrburke/module">module</a>: Not AMD, but what I imagine a module system would look like given what we have learned from CommonJS and AMD modules, and assuming a browser loader capability that avoids CORS/CSP issues for text fetching and evaluation. While a useful exercise, and more operational and fleshed out than an ES system, more of an experimental playground.</li>
</ul>

<h2 id="amodroloader">amodro loader</h2>

<p>For a new AMD loader, I am thinking of putting it under the amodro (pronounced a-mo-dro) name. amodro-trace is the start of what I would see as its equivalent of the requirejs optimizer piece. amodro-trace currently uses requirejs under the hood for module tracing, but ideally that would migrate over time to a new loader.</p>

<p>I would not want to modify any of the AMD APIs for declaring a module or for the dynamic require calls. So no changes in module syntax to allow the most reuse of existing AMD modules.</p>

<p>However, I want to rethink some of the loader APIs and loader plugin APIs to do something like what an older draft of the ES-related loader had for a module lifecycle: normalize, locate, fetch, translate, instantiate. The loader plugin API as supported in requirejs-like loaders is not as granular, and supporting a more granular API would help with some issues that have come up with the loader plugins to date: it can be hard to break cycles for some loader plugins, and can make building more complicated.</p>

<p>The <code>module</code> loader mentioned above makes an attempt at that sort of solution for loader plugins, and it works out well. There is a good chance existing loader plugins would still work too since their APIs can be seen as a coarser API that could be supported by the more granular API. Still a bit of work to be done there, but it seems promising.</p>

<p>So I expect amodro would be like the <code>module</code> loader, but designed to work with the AMD APIs instead of the <code>module</code> API in that loader, and probably using some of the alameda ideas too.</p>

<p>I may not get to it though. Just sharing my thoughts around loader work. I have a day job that I really like, and we are doing some interesting work. There are some (non-loader) ideas I want to implement there, and I am excited to try out service workers in that context.</p>

<p>The <a href="http://dojotoolkit.org/">Dojo folks</a> are also thinking about this space, as well as <a href="http://unscriptable.com/">John Hann</a> and <a href="http://tbranyen.com/">Tim Branyen</a>, so other options may come out of their efforts too. It is good to have options.</p>

<p>End result, more in this space worth pursuing.</p>

<h2 id="moreconventionoverconfiguration">More convention over configuration</h2>

<p>For AMD projects in general, and something that does not depend on any new loader work:</p>

<p>We can help improve the perception of difficulties with configuration by starting to advocate more for standard project layouts that avoid big configuration blocks for the loader. Effort in this space would likely benefit an ES module solution too, as it will need to operate in the same async network space that AMD modules operate.</p>

<p>To me, that means using a starting project layout that looks like <a href="https://github.com/volojs/create-template">this sample project</a>. The <code>lib</code> directory could be a <code>node_modules</code> or <code>bower_components</code> directory.</p>

<p><a href="https://github.com/jrburke/adapt-pkg-main">adapt-pkg-main</a> can be used after an npm/bower install to fix up the installed dependency to work with the file layout convention that works best for general web module loading, without running into CORS or 404 issues.</p>

<p>Then hopefully the package managers get better about these file layouts over time (maybe absorb what adapt-pkg-main does), and in the case of npm, <a href="https://github.com/jrburke/notobo/blob/master/docs/npm-sharp-edges.md">remove some sharp edges</a> for front end development.</p>

<h2 id="summary">Summary</h2>

<p>You might try <a href="https://github.com/amodrojs/amodro-trace">amodro-trace</a> if its use cases fit your needs. While it comes from some code that has had a good amount of testing, it is still a new approach on it and may have some bugs, so I am keeping the version low for now. However, it is the kind of AMD build tool I would like to support longer term: provide a primitive focused solely on the AMD tracing and normalization so that others can build on top of it.</p>

<p>The requirejs optimizer was built at a time when node was not a thing yet, and more batteries needed to be included for command line JavaScript tooling. It has been a good approach for the requirejs optimizer: it runs in node, Nashorn, Rhino, xpcshell and even in the browser. It gives a bunch of communities a chance at some good AMD-based optimization options.</p>

<p>However, I do not expect to keep pace with all the possible variations in build tool styles with the requirejs optimizer's more declarative options-based approach. amodro-trace should be helpful for those cases.</p>

<p>Here's to more AMD loaders and tools for the future!</p>]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[How to know when ES modules are done]]></title>
        <link href="https://jrburke.com/2015/02/13/how-to-know-when-es-modules-are-done/"/>
        <updated>2015-02-13T21:49:08.820Z</updated>
        <id>https://jrburke.com/2015/02/13/how-to-know-when-es-modules-are-done/</id>
        <content type="html"><![CDATA[<p>There are few pieces of a module system that need to be available for it to be fully functional. I will describe them here and talk a bit about where ECMAScript (ES) modules seem to be at the moment, from an outside public perspective.</p>

<p>I am not on TC-39, the committee that works on the ES language specification (otherwise known as JavaScript, JS). Just someone who has worked on <a href="http://dojotoolkit.org/">a</a> <a href="https://github.com/requirejs/cajon">few</a> <a href="http://requirejs.org/">JS</a> <a href="https://github.com/requirejs/alameda">module</a> <a href="https://github.com/jrburke/module">systems</a>.</p>

<p>This is a long piece. A table of contents for the top level sections:</p>

<ul>
<li><a href="#modulesystempieces">Module system pieces</a></li>
<li><a href="#interlockingpieces">Interlocking pieces</a></li>
<li><a href="#wherearewenow">Where are we now?</a></li>
<li><a href="#hazardsonthewaytodone">Hazards on the way to done</a></li>
<li><a href="#summary">Summary</a></li>
</ul>

<h2 id="modulesystempieces">Module system pieces</h2>

<p>There are three main pieces of a module system:</p>

<ul>
<li><a href="#staticmoduledefinition">Static module definition</a></li>
<li><a href="#executiontimemodulecapabilities">Execution-time module capabilities</a></li>
<li><a href="#moduleloader">Module loader</a></li>
</ul>

<p>Some might argue that these pieces are separable and could be specified by different standards groups. So an "ES module system" may not be the right term, as ES may only specify one or two pieces.</p>

<p>For me, they are all part of a coherent module system, so I will be referring to the future direction for them as the "ES module system", even if the URLs for each specification end up on different domains.</p>

<h3 id="staticmoduledefinition">Static module definition</h3>

<p>This is how you statically declare a piece of code as a module with dependencies. In this context <strong><em>static</em></strong> means: does not change depending on the execution environment. Static dependencies can be parsed out of a module without actually running the module in a JS environment, the loader just needs to parse the text of the module to find them.</p>

<p>In AMD modules, it looks like this:</p>

<pre><code class="language-javascript">define(function(require, exports, module) {
  // Statically parsable dependencies.
  var glow = require('glow'),
      add = require('math').add;
});
</code></pre>

<p>In CommonJS and Node (for shorthand's sake referred to as "CJS" for the rest of this post), there is a similar idea, just without the define() wrapper.</p>

<p>It is a bit more nuanced in CJS systems: the require(StringLiteral) calls are not parsed prior to execution, one of the major reasons that format is not fully suitable for a full module system on the front end, where async networking is involved. You can get some front end functionality by using something like browserify or webpack to do the static search for dependencies, but just for bundling. Fine enough for libraries but starts to break down on the app level where you want to incrementally load functionality as the user goes to use it, use a dynamic router.</p>

<p>In ES, it looks like this currently:</p>

<pre><code class="language-javascript">// Statically parsable dependencies.
import glow from 'glow';
import { add } from 'math';
</code></pre>

<p>ES also statically indicates the named export keys too:</p>

<pre><code class="language-javascript">// Statically parsable dependencies.
import glow from 'glow';
import { add } from 'math';

// Statically indicate this module will have a 'default'
// and 'other' export keys.
export default function() {};
export other funtion() {};
</code></pre>

<p>While this helps statically match up any keys given to the exported values to the ones used in import statements, the export value is not statically exported, just an indication of its name.</p>

<p>For AMD/CJS systems, there really is just one exported value per module, but it could be an object with multiple properties. There is no static analysis of the export value in those systems.</p>

<p>This part of the ES module system is the piece that is the most specified at the moment.</p>

<h4 id="inlinemodules">Inline modules</h4>

<p>However, the ES system does not allow for what will be called "inline modules" for the purposes of this post. Inline modules are just the ability to statically declare more than one module in a file. This is commonly used for bundling modules together, but <a href="https://github.com/jrburke/module/blob/master/docs/inlining.md">has other purposes</a>.</p>

<p>In AMD, those are just named <code>define()</code>s:</p>

<pre><code class="language-javascript">define('glow', function(require, exports, module) {
  return function glow() {
  };
});

define('app', function(require, exports, module) {
  // Statically declare dependencies.
  var glow = require('glow'),
      add = require('math').add;
});
</code></pre>

<p>For CJS, there are conventions for doing this via tools like browserify and webpack, but they are much less declarative. The module IDs are converted to array indices/numbers. This makes dynamic module loading harder.</p>

<p>For ES there is nothing for this. The last I heard, the hope was for capabilities like HTTP2 and zip bundles so that no new language syntax is needed, however I believe <a href="https://github.com/jrburke/module/blob/master/docs/inlining.md">that is not sufficient</a>.</p>

<p>In the AMD/CJS world, it has become more common to deal with nested groups of modules bundled together. An example would be some browserified base libraries that are then combined with some AMD modules in an app. The browserified ones have a conceptual inner module structure that should not be visible outside the module.</p>

<p>AMD and CJS do not do well with this right now. I have considered supporting something like this in my AMD loaders to allow for it:</p>

<pre><code class="language-javascript">define(function(require, exports, module, define) {
  // The define passed in here is a local
  // define for modules only visible to
  // this module.
});
</code></pre>

<p>There are some interesting characterstics around how to define the module this way when it can have async resolved dependencies. That has been more fully explored in <a href="https://github.com/jrburke/module">this module experiment</a>, so I believe it can work.</p>

<p>The end result, I see modules now as units of code that can be nested. Similar to how functions work, but instead of identifiers for names, module ID strings are used, and their export may be resolved asynchronously, so a bit of syntax is needed for that.</p>

<p>The other option I have heard for ES would be to compile down the module into ES5 code, and use the ES module loader lifecycle hooks to get that into an ES6 module loader.</p>

<p>That option looks like a leaky abstraction. In addition, there are some tricks with the way ES6 imports are mutable slots and the syntax around getting to the execution-time module capabilities that require some extra thought.</p>

<h3 id="executiontimemodulecapabilities">Execution-time module capabilities</h3>

<p>There are some properties and capabilities that need to be exposed during the execution of a module. This means it cannot be statically determined, it is only known once the module is executing in a JS engine.</p>

<p>In the AMD world, the execution-time capabilities come in these forms:</p>

<ul>
<li><code>module.id</code> - the module's normalized ID for the module loader instance.</li>
<li><code>module.url</code> - the URL or path to the module.</li>
<li><code>require([aJsStringValue], function(c) {})</code> - dynamically get a handle on modules. Load them if need be, but in the loader that loaded this module. Should also handle relative IDs.</li>
<li><code>require.toUrl('./d')</code> - Converts module ID './d' to a full path, useful for assets related to the module, like images or style sheets.</li>
</ul>

<p>In Node:</p>

<ul>
<li><code>module.id/module.url</code> - they end up being the same, but conceptually should be different.</li>
<li><code>__filename</code> - could be derived from module.url.</li>
<li><code>__dirname</code> - could be derived from module.url.</li>
<li><code>require(aJsStringValue)</code> - dynamically, synchronously load and execute module in the loader that loaded this module.</li>
<li><code>require.resolve(AJsStingValue)</code> - converts module ID to a path.</li>
</ul>

<p>(Synchronous return from that dynamic require is one of the reasons the CJS system is not the right fit for a general purpose front end module system in the browser.)</p>

<p>In ES, this piece is not formally specified yet. In the ES world, I believe this is referred to as the "module meta", if you come across that phrase. The most recent hint of how it might be done in ES looked something like:</p>

<pre><code class="language-javascript">import local from this;
console.log('Normalized module ID is: ' + local.id);
console.log('Normalized module URL is: ' + local.url);
local.import(aJsStringValue).then(Function(someModule) {});
</code></pre>

<p>I am making up the name of the properties for id, url, and import. I am not sure what their real names will be, just that <code>from this</code>, or some <code>from</code>-based form, was being considered as the way to aquire this functionality.</p>

<h3 id="moduleloader">Module loader</h3>

<p>This is an API that runs at execution time. It kicks off module loading, and allows ways to resolve module IDs to paths, handles the loading and proper execution order of the modules, caches the module values.</p>

<p>In AMD, the main module loader API is <code>require([String], function(e) {})</code>. There is usually something like <code>require</code> for top-level, default loader loading, and each module can get its own local <code>require</code>. Some AMD loaders can create multiple module loader instances.</p>

<p>It is common for AMD loaders to support the idea of a loader plugin, a module that provides a <code>normalize</code> and <code>load</code> method that are plugged in to the AMD loader's <code>normalize</code> and <code>load</code> lifecycle steps.</p>

<p>This allows extending the base loader to handle transpiled code without requiring plugins to be loaded up front, before main module loading starts.</p>

<p>In CJS, <code>require(String)</code> is the main API to the module loader. There is a way to extend the loader capabilities via <code>require('module')._extensions['.fileExtension'] = function() {}</code>. This requires the extension to be installed before modules that depend on it are loaded. This works fine in Node's synchronous module execution environment, but does not translate to async loading in the browser.</p>

<p>For ES, this part is still being defined. There was a <a href="https://github.com/jorendorff/js-loaders">previous sketch for it</a>, but it seems like that is being redone now. I do not feel it is useful to link to the current attempt at the sketch because it is incomplete, and they likely want to work on it themselves to get it in a more usuable state before getting a lot of feedback about it.</p>

<p>The previous sketch did have the concept of a module loading lifecycle, and a way for userland code to plug in to that lifecycle, and I can see this concept carrying forward in some fashion:</p>

<ul>
<li><code>normalize</code>: normalize module IDs.</li>
<li><code>locate</code>: translating an ID to a URL/path.</li>
<li><code>fetch</code>: getting the text contents of the module from the URL/path.</li>
<li><code>translate</code>: allows translating the text into JavaScript that can be executed.</li>
<li><code>instantiate</code>: allows a way for legacy module syntaxes to be converted into a form usable by the ES loader.</li>
</ul>

<p>The granularity of these steps are better than the ones in AMD loader plugins, which just have a concept of <code>normalize</code> and <code>load</code>. <code>load</code> is really <code>locate</code>, <code>fetch</code>, <code>translate</code>, <code>instantiate</code> in one method. It would be good to have more granular steps.</p>

<p>However, there was no built in way in the ES loader to know how to load the hooks as part of normal module loading.</p>

<p>For AMD systems, module IDs of the form <code>pluginId!resourceId</code> meant the loader would load the module for <code>pluginId</code>, then wire it into the loader lifecycle, then delegate to that plugin's lifecycle methods for IDs that begin with <code>pluginId!</code>.</p>

<p>That approach avoids a two-tiered loading system in a web page where the all the loader plugins are loaded first, and then continue with the rest of module loading. The two tiered approach is slower and breaks encapsulation. Any package that used a loader plugin would need to somehow get the plugin registered in the correct loader instance up front. It also gets tricky if those loader plugins have regular JS module dependencies.</p>

<h2 id="interlockingpieces">Interlocking pieces</h2>

<p>While the three pieces of a module system could in some way be considered separate, they all have interlocking pieces, and those pieces need to fit well together.</p>

<h3 id="moduleids">Module IDs</h3>

<p>The rules around the module IDs needs to be understood for the pieces to work well together. If someone is just working with the static module definition part and just uses a plain path for the ID, that will likely conflict with the module loader part, since the IDs should be separate string concepts from paths to support conceptual string namespaces for things like loader plugins and packages that do not have direct path equivalents.</p>

<h3 id="loaderextensions">Loader extensions</h3>

<p>This is tied a bit into the module ID coordination, but also involves module loader load order and how much a given module needs to know about how loader extensions (like transpilers) get wired into the system.</p>

<p>One option is to say that is something that is configured and wired up separately from the modules themselves, out of band, like via package config and some coordinated way to get those registered with a loader up front. This breaks encapsulation though, and makes it hard for the plugins to use modules for their own dependencies. The loader plugin approach in AMD is a much more sane way to go about it.</p>

<h3 id="executiontimemodulecapabilitiesvsstaticmoduledefinition">Execution-time module capabilities vs static module definition</h3>

<p>In the ES sketch above, <code>from this</code> for the execution-time module capabilities is a specific language construct that needs to be built into the static module definition.</p>

<h3 id="loadersandexecutiontimemodulecapabilities">Loaders and execution-time module capabilities</h3>

<p>The execution-time module capabilities also relate to methods on the module loader, like the capability to dynamically load code.</p>

<h2 id="wherearewenow">Where are we now?</h2>

<p>I believe the plan is for the ES6 spec is to just contain the static module definition piece, and for the other bits to be specified in separate specifications coming later.</p>

<p>The trouble is people are starting to use the static module definition piece via transpilers, but without having the other interlocking pieces sorted out.</p>

<p>The transpilers often just compile down to AMD or CJS modules for actual use, and these have some differences with the likely final ES plan. The main issues are:</p>

<h3 id="moduleidsarenotsortedout">Module IDs are not sorted out</h3>

<p>AMD has a stricter separation to module ID vs path, where CJS as practiced in Node is more file path based. IDs really need to be different things than paths. For regular JS modules, they can have an easy simple transform to a path, but need to be conceptually different.</p>

<h3 id="exportmodelsaredifferent">Export models are different</h3>

<p>The ES export module is different than AMD/CJS. In ES all exports are named. The name <code>default</code> just has some extra syntax sugar for <code>import</code>, but no sugar when the module is referenced via the execution-time module capabilities. Expect to be typing <code>.default</code> for that.</p>

<p>AMD/CJS exports are really just single exports, but those systems are nice enough to create an export object if you want to use the <code>exports.foo = ''</code> form of adding properties to the export object.</p>

<h3 id="noexecutiontimemodulecapabilities">No execution-time module capabilities</h3>

<p>There is no ES specification for the execution-time module capabilities. So there is no way with the ES syntax and APIs to build a dynamic router. You will need to know the AMD/CJS system you are using underneath to do that part.</p>

<p>What is meant by "dynamic router"? A module that looks at a piece of runtime path information (typically a URL segment), then translates that to a module ID for a view and dynamically loads that view via module APIs (either <code>require([varName])</code> in AMD or <code>require(varName)</code> in CJS).</p>

<p>Dynamic routers are really handy to avoid loading all possible routes and views up front, helps with performance.</p>

<p>Using the module ID via <code>module.id</code> is useful in cases where there are global spaces, like the DOM, and the module wants to construct class names, DOM data that will be in that global space. Basing its values on the module ID helps scope selectors and data access for that module.</p>

<h3 id="nostaticdefinitiontoallowinlinemodules">No static definition to allow inline modules</h3>

<p>This is a big missing piece in ES. Right now, expect to use AMD/CJS approaches here.</p>

<h2 id="hazardsonthewaytodone">Hazards on the way to done</h2>

<p>So, do not consider the ES module system done that with the publication of the ES6 spec. It just has one part of the system, and in many ways the most straight-forward piece. It is somewhat complicated by all the forms for <code>export</code> and <code>import</code>, but that was a design choice given TC-39's goals.</p>

<p>The real action comes with the module loader parts: if that is worked out, you might be able to skip the ES6 static definition parts.</p>

<p>So hopefully the other parts of the module system will come along. Some hazards to avoid on the way:</p>

<ul>
<li>Module IDs are not kept separate from paths/URLs, or if the loader uses paths/URLs instead of IDs for its internal keys.</li>
<li>No solid story for inline modules.</li>
<li>You need a script loader bootstrap even for the most basic wiring of all of the three pieces together.</li>
<li>The module loader needs a two-stage loading mechanism where the first stage loads up all possible loader lifecycle plugins before starting the second stage to load regular modules.</li>
<li>The <code>&lt;module&gt;</code> tag in HTML comes into existence before the module loader. Keeping with the extensible web philosophy, the module tag should just fall out of the module loader primitive and perhaps custom elements.</li>
<li><a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Access_control_CORS">CORS</a> configuration is required to use plain JS modules across domains. CORS should only be required if the <code>translate</code> loader lifecycle hook wants to look at it. Otherwise, the <code>translate</code> hook is skipped for those scripts.</li>
</ul>

<h2 id="summary">Summary</h2>

<p>Making a module system for ES is hard, and it is not done yet. I wish the process would have been different to date with more dialog outside of TC-39. However, it seems like the people working on it are just not done with all the pieces. I can appreciate it is hard to talk about it until the fuller picture is worked out.</p>

<p>The unfortunate part for me is seeing people starting to use the ES6 static module definition and transpiling to ES5 module systems to ship code. I think it is just too early to do that.</p>

<p>In the grand tradition of languages that can transpile to JS, you can get something to work and ship code to users. You can use CoffeeScript too. So if you are having fun with the transpiling route, that is great. Just know the sharp edges.</p>

<p>You are adding another layer of abstraction on top, and in the case of modules, you will likely need to directly use or know the properties of the ES5 module system you are using underneath to get the full breadth of module system functionality.</p>

<p>For me, fewer layers of abstraction are better. I will be waiting until more of the ES pieces are defined and shown to work well together before considering them done and using it to ship code.</p>]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Referencing JavaScript]]></title>
        <link href="https://jrburke.com/2012/11/02/referencing-javascript/"/>
        <updated>2012-11-02T16:40:55.062Z</updated>
        <id>https://jrburke.com/2012/11/02/referencing-javascript/</id>
        <content type="html"><![CDATA[<p>Referencing JavaScript. How should it be done? Is there an approach that works for module systems, package managers and project layouts?</p>

<p>The following describes the approach in use by <a href="https://github.com/amdjs/amdjs-api/wiki">AMD</a>/<a href="http://requirejs.org">RequireJS</a> and <a href="http://volojs.org">volo</a>, but parts are found in other places like <a href="http://www.nodejs.org/">Node</a>, <a href="http://www.commonjs.org/">CommonJS</a> and <a href="http://dojotoolkit.org/">Dojo</a>.</p>

<p>The following approach works well for browser-based, web development. Since browser-based development is the harder environment to support, the approaches can carry over well to other JS environments. Other environments have the capability to add more power to this approach, but it would be nice to see a baseline available across all JS environments.</p>

<p>If you work on module systems, package managers/tools or project layouts, please consider this approach. There could be other ways to accomplish the same end result, but the following approach is cohesive and have been proven out in practice.</p>

<h2 id="summary">Summary</h2>

<p>The high level summary:</p>

<ul>
<li><strong><a href="#defaultsforsinglefilelibraries">Defaults for single file libraries</a></strong>. This encourages small reusable modules, and leads to a simpler project layout.</li>
<li><strong><a href="#referencecodeusingstringids">Reference code using string IDs</a></strong>. These IDs are not paths, but have an easy convention to map to paths. Treat the IDs as an ID namespace, not as path entities.</li>
<li><strong><a href="#useasimpleidtopathconvention">Use a simple ID-to-path convention</a></strong>. baseUrl + ID + ".js".</li>
<li><strong><a href="#allowdeclarativeconfiguration">Allow declarative configuration</a></strong>. Some things do not fit in convention.</li>
</ul>

<p>More detail below, and how these points affect module systems, package managers/tools, and project layouts.</p>

<h2 id="defaultsforsinglefilelibraries">Defaults for single file libraries</h2>

<p>The ideal project layout should be a collection of single file JS libraries that each do one thing well. Ideally the functionality is exported as a single value, commonly a function.</p>

<p>There will be libraries that want to do a few things and provide a few modules in one package. Those should be possible to support, but the defaults are optimized for single file JS libraries.</p>

<p>If the defaults and conventions are around single file JS libraries, it will give a nudge to consider that direction. It is also simpler for new people to understand. With the configuration mentioned later, the system can grow as they grow.</p>

<h3 id="singlefilelibsmodulesystems">Single file libs: module systems</h3>

<p>Allow exporting a single function as the module value. This works in Node by assigning the export to <code>module.exports</code>. In AMD, it works by returning a value from the factory function.</p>

<p>Ideally Node would have just used <code>return</code> too, but it is difficult to support in JS since <code>return</code> is not allowed at the top level of a script. Technically, it would work to use <code>return</code> in Node, since under the covers node wraps the module code in a function before evaluating it, but the source files would not lint or parse well -- source editors and tools that check syntax would complain.</p>

<p>For circular dependencies, there are cases where returning the value makes it hard to resolve the cycle. The <code>exports</code> concept in CommonJS is useful for those cases, so that kind of capability should be available. However, the majority of modules in AMD and Node just set the module value, so there should be an easy way to just set the value, and in particular allow function values for modules.</p>

<h3 id="singlefilelibspackagemanagers">Single file libs: package managers</h3>

<p>Allow registering single file JS files as a "package". For communicating module metadata, allow an inline <code>/*package */</code> comment to express the JSON metadata instead of mandating a separate package.json file.</p>

<p>volo supports this already. <a href="http://npmjs.org/">npm</a> supports this in a limited fashion, and I believe <a href="http://twitter.github.com/bower/">Bower</a> uses the same <a href="https://github.com/isaacs/read-package-json">metadata extraction library</a> as npm.</p>

<p>When installing a package into a project, just install the single JS file as the name given with a ".js" extension. So <code>install foo</code> should result in just a foo.js on disk, instead of creating a folder just for foo.js.</p>

<p>This is important for the "simple convention" approach later. It is also just cleaner.</p>

<p>npm could improve the state of its installation artifacts. Do not encourage projects to package a readme or tests such that those things show up installed in a project. This is unnecessary noise that is not needed once the dependency is installed.</p>

<p>There needs to be a way to get more info on a dependency, but that should be fetched via commands to npm, not having to scan extra local file debris. If someone wants to run tests in their project, querying npm to find or install the source repo is a better way to go about this.</p>

<p>For package managers in general, there needs to be a way to allow a directory as the package install. There are cases that have binary components, and even richer packages that are made up of more than one module.</p>

<p>However, the defaults should make it easy to use single file JS files. This is something Bower could improve on. Currently Bower creates a directory for each dependency, and every dependency directory has an "index.js" in it. This is bad for debugging and creates a bunch of directory and file debris that is not useful for running the application.</p>

<p>If a package manager needs to track metadata for a dependency, either rely on inline <code>/*package */</code> metadata, or use a project's package.json file to store the dependency ID/version number/location, and then use that later to look up info about the dependency.</p>

<h3 id="singlefilelibsprojectlayouts">Single file libs: project layouts</h3>

<p>Projects should be able to specify a directory in which dependencies should go. More on this in the convention and configuration sections.</p>

<h2 id="referencecodeusingstringids">Reference code using string IDs</h2>

<p>This is how it is done in CommonJS/Node and in AMD/RequireJS. So to use jQuery as dependency, specify "jquery" as the dependency ID. Do not include the ".js" extension. This allows for different path resolutions.</p>

<p>In Node, it may result in a nested directory IO lookup, and reading of a package.json "main" property. In AMD solutions, it may simply map directly to a 'jquery.js' under a "baseUrl", or be subject to some declarative configuration.</p>

<p>IDs should allow relative references. So, a module with ID of "some/thing", can use "./other" to refer to the "some/other" module.</p>

<p><strong>Module IDs are not path entities</strong>. They are keys in a module ID space. This is a subtle point, and it creeps up once multiple modules are inlined into one file, either for library distribution or for optimization purposes. Those IDs should be maintained as module IDs, and not as path entries. This is something I think is missing in Node, where internally it uses paths as the underlying key for a module. This carries over to how tools like <a href="https://github.com/substack/node-browserify">browserify</a> inlines modules.</p>

<p>Since module IDs are not paths, it means resolving relative IDs using a reference module ID and not a path.</p>

<h3 id="stringidsmodulesystems">String IDs: module systems</h3>

<p>Use strings as IDs when referencing and defining modules. Always use those string IDs, even in built source form. This allows for supporting loader plugins.</p>

<p><a href="http://requirejs.org/docs/plugins.html">Loader plugins</a> have been incredibly useful for AMD loaders, and I believe they are better than the file extension-based system that Node uses currently, since loader plugins are more direct in usage. Their use is controlled by the caller, not by some module acting at a distance.</p>

<p>For example, a "<a href="https://github.com/requirejs/text">text</a>" loader plugin can load a .html file or a .txt file, and a "mustache" loader plugin could also handle the same .html file as the text plugin. How the file will be used is subject to the caller's context, not the file extension.</p>

<p>Loader plugins can do conditional logic before satisfying the dependency. This opens up feature detection-based dependencies that are expressible as string IDs and participate in optimization/build steps.</p>

<p>Loader plugins are a great way to implement transpilers too. Examples from the AMD/RequireJS world: <a href="https://github.com/jrburke/require-cs">CoffeeScript</a>, <a href="https://github.com/iammerrick/require-ts">TypeScript</a>.</p>

<h3 id="stringidspackagemanagers">String IDs: package managers</h3>

<p>Since there is a layer of indirection between the module ID and the path, this opens up some flexibility on install location. However, as mentioned in the path convention section below, using a "baseUrl" convention is useful.</p>

<h3 id="stringidsprojectlayouts">String IDs: project layouts</h3>

<p>The string IDs are useful when combined with the default ID-to-path convention for keeping IDs short, but easy to map to locations on disk. No need to type out the directory and ".js" for each dependency. Just look in the directory used as the "baseUrl" to find all the dependencies.</p>

<h2 id="useasimpleidtopathconvention">Use a simple ID-to-path convention</h2>

<p>Module IDs are not paths, but it should be easy to map an ID to a path.</p>

<p>This should just be baseUrl + [module ID] + ".js".</p>

<p>Why is ".js" given special status? Because this is about loading JavaScript, and .js is already the recognized file type for JavaScript. Loader plugins allow referencing of non-JS files. The loader plugin just has to turn the dependency into some sort of JavaScript result.</p>

<p>For JS endpoints that are URLs that do not end in ".js", but deliver JavaScript, those can be configured via the declarative configuration. These are rare, and they may need a loader plugin to properly load if they have multiple async cycles to fully complete, like the Google APIs.</p>

<p>Since libraries are encouraged to be single JS files, this simple convention makes it easy for anyone to guess where the dependency exists in a default layout. If a developer is looking inside <strong>www/js/bar.js</strong> and it references "foo", then odds are it is at <strong>www/js/foo.js</strong>, or somehow tied to <strong>www/js/foo</strong>.</p>

<p>It is easier for new developers to start with JS: "just drop all scripts in this directory and refer to them without the '.js'". It also helps enforce single purpose, single file libraries.</p>

<h3 id="pathconventionmodulesystems">Path convention: module systems</h3>

<p>This approach means there is one IO lookup per module ID. This is important on the web, where trying multiple file/URL locations for a module ID would lead to terrible performance and confusing 404 errors in developer tools.</p>

<p>This also means avoiding looking up modules in a global file location. This is not really an issue for browser environments, everything is "local" to the project. However, for non-browser JS environments, using a global file location to look up modules for specific projects is not recommended.</p>

<p>Node's local node_modules approach is the right direction to go, versus the Python and Ruby models that favor the global space more. Most of my headaches when using Python and Ruby stem from this choice. While virtual environments are a way to work around that, it is a non-default behavior and a continual tax to use them.</p>

<h3 id="pathconventionpackagemanagers">Path convention: package managers</h3>

<p>The biggest outcome of this approach is avoiding a global installation space, and to install all dependencies locally within a project.</p>

<p>This is done in npm and Node. While npm allows installing into a global directory, those packages are not visible to a specific project's require calls. So those kinds of installs are mostly useful for command line tools that are built using Node.</p>

<p>The package manager should be able to read the "baseUrl" location either by a convention with project layout or via an explicit metadata property in the project's package.json. "baseUrl" is recommended as the property name, since it ties in with the runtime configuration of a module loader.</p>

<p>volo supports a "baseUrl" property in the package metadata, and if specified, will install all dependencies in that directory. If no baseUrl property, then volo will use one of these locations:</p>

<ul>
<li><strong>js</strong> directory, if exists</li>
<li><strong>scripts</strong> directory, if exists</li>
<li>current working directory</li>
</ul>

<p>There are some dependencies that will want to be directories, since they may have binary components, or they are larger libraries that provide a few related modules.</p>

<p>These directory-based libraries can be supported in one of two ways:</p>

<p>1) Allow updating a config object that is used at runtime with extra info. <a href="http://jamjs.org/">Jam</a> does this. See the declarative config section below for more info on config values.</p>

<p>2) Install a proxy module that points to the directory's "main" module. So if installing a package "foo" that is a directory and its package.json has a <code>"main": "index"</code> property, use this directory layout:</p>

<ul>
<li><strong>foo.js</strong> (created by the package manager)</li>
<li><strong>foo/</strong> (fetched from the package repository)
<ul><li>index.js</li></ul></li>
</ul>

<p>And <strong>foo.js</strong> just requires "foo/index" and returning the "foo/index" module value. Volo takes this route.</p>

<h3 id="pathconventionprojectlayouts">Path convention: project layouts</h3>

<p>Use the project's package.json to store a property that indicates the baseUrl. Calling it <code>baseUrl</code> matches what the runtime module system will use.</p>

<p>I favor the project layout as specified in <a href="https://github.com/volojs/create-template">volojs/create-template</a>:</p>

<ul>
<li><strong>tools</strong>: directory to hold local project/build tools and assets.</li>
<li><strong>www</strong>: the source directory, what is served up by a web server in dev.
<ul><li><strong>js/lib</strong>: the "baseUrl" used by the project.</li></ul></li>
<li><strong>www-built</strong>: the built version of the project. It should be possible to do most development in the www directory, and when ready for deployment and optimization, trying out the built version in www-built.</li>
</ul>

<p>The package.json for that project layout uses <code>"baseUrl": "js/lib"</code> to indicate the the place to install dependencies.</p>

<h2 id="allowdeclarativeconfiguration">Allow declarative configuration</h2>

<p>Not all styles fit into the default convention. We have seen this in AMD, and AMD loaders are working towards a <a href="https://github.com/amdjs/amdjs-api/wiki/Common-Config">common set of config options</a>.</p>

<p>By allowing a declarative configuration, it removes the need for additional "helper libraries" that would likely be needed in the browser to configure an imperative hook for ID resolution.</p>

<h3 id="declarativeconfigmodulesystems">Declarative config: module systems</h3>

<p>Support a declarative set of configuration values that are used at runtime, like the ones in the <a href="https://github.com/amdjs/amdjs-api/wiki/Common-Config">AMD Common Config</a>:</p>

<ul>
<li><strong>baseUrl</strong>: sets the baseUrl for the ID-to-path conversions.</li>
<li><strong>paths</strong>: configures a base path for a module ID prefix.</li>
<li><strong>map</strong>: maps IDs used by some ID prefixes to other ID prefixes. It may be worth renaming this to "alias" to make it clearer how it differs from paths.</li>
<li><strong>config</strong>: passes some configuration data to a particular module ID. This is useful for passing data that changes depending on the environment or context. User IDs and API end points are good examples.</li>
<li><strong>packages</strong>: configures CommonJS/Node style "package" directories with a "main" property without using an adapter/proxy module.</li>
</ul>

<p>For supporting code that may not actually call the module system, RequireJS users have found <a href="http://requirejs.org/docs/api.html#config-shim">shim config</a> to be useful.</p>

<p>A module system may still have an imperative hook to override final ID-to-path resolution. I can see this useful for environments like Node: use the declarative config, and if that does not translate to a file that exists, then fall back to the "scan nested node_modules directories" approach.</p>

<p>However, given the IO restrictions for browser environments, a declarative config should be available as a default.</p>

<h3 id="declarativeconfigpackagemanagers">Declarative config: package managers</h3>

<p>Stamp the project config if installing a dependency would require a configuration entry. Examples: support "directory packages" or to set up a map/alias so that certain modules use version 1 of a library while the rest of the modules in the project use version 2.</p>

<p>To do this, the package manager needs to know the location of the configuration.</p>

<p>While this is not implemented yet in volo, I favor piggybacking on a "baseUrl" that is specified in a project's package.json file. By default, assume the config is in baseUrl + 'main.js'. However, allow for a configuration override via a package.json property. Perhaps call it "mainConfigFile", as <a href="http://requirejs.org/docs/optimization.html#mainConfigFile">the r.js optimizer does</a>, and it would be a path within the project to the JS file that has the configuration.</p>

<p>The configuration will be passed to a runtime JS module API call, so to be able to properly extract the config, update it, and save it back, the package manager needs to handle updating a file that is written in JavaScript. This is possible by using tools like <a href="http://esprima.org/">Esprima</a> or <a href="http://marijnhaverbeke.nl/acorn/">Acorn</a>.</p>

<h3 id="declarativeconfigprojectlayouts">Declarative config: project layouts</h3>

<p>The baseUrl approach works well for getting started, but many projects like to keep third party dependencies separate from the application code. For that kind of project layout, set the baseUrl to a <strong>lib</strong> directory to hold third party code, and then specify an "app" paths config for an <strong>app</strong> directory that is a sibling to <strong>lib</strong> for the app code.</p>

<p>The <a href="https://github.com/volojs/create-template">volojs/create-template project template</a> does this in the main <a href="https://github.com/volojs/create-template/blob/761945fac2557bc50e22bcae4984305a03e0f45d/www/js/app.js">app.js file</a>. The project
layout:</p>

<ul>
<li><strong>www</strong>
<ul><li><strong>index.html</strong>: uses require.js to load www/js/app.js via <code>data-main="js/app"</code></li>
<li><strong>js</strong>
<ul><li><strong>app.js</strong>: loaded by index.html, has the declarative config.</li>
<li><strong>app</strong>: directory to hold app code
<ul><li><strong>main.js</strong>: module that runs the main logic for the app.</li></ul></li>
<li><strong>lib</strong>: directory to hold third party code.</li></ul></li></ul></li>
</ul>

<p>where app.js holds the small configuration for the app:</p>

<pre><code class="language-javascript">// For any third party dependencies, like jQuery,
// place them in the lib folder.

// Configure loading modules from the lib directory,
// except for 'app' ones, which are in a sibling
// directory.
requirejs.config({
    baseUrl: 'js/lib',
    paths: {
        app: '../app'
    }
});

// Start loading the main app file. Put all of
// your application logic in there.
requirejs(['app/main']);
</code></pre>

<p>Any app modules are stored in the <strong>app</strong> directory. The app modules refer to each other using relative module IDs.</p>

<p>Some projects that use RequireJS end up with large config blocks, mostly with a paths setting for each dependency. This should be discouraged.</p>

<p>With the lib baseUrl and the app paths setting, it gives the smallest amount of config that does not need continual updates and still separates third party code from the application's code.</p>

<p>One of the reasons some people use big config blocks is so they can track the version number of the dependency in the file name, like <code>jquery: 'lib/jquery-1.8.2'</code>. Instead, track this information in a project's package.json file, since it is most useful to track as part of a package manager's work, to resolve version conflicts.</p>

<h2 id="secondaryimplementationnotes">Secondary implementation notes</h2>

<h3 id="projectorlibrarymetadata">project or library metadata</h3>

<p>In the above points, a <code>package.json</code> is mentioned a few times. This is a project or library level file that holds the JSON-based metadata about the project. It is not information that is needed at runtime, but information about what the project or library needs to have installed to function at runtime.</p>

<p>For single file lib support, this metadata should be allowed inline in the JS file as a comment:</p>

<pre><code class="language-javascript">/*package
{}
*/
</code></pre>

<p>While npm relies heavily on package.json and assumes certain formats for "dependencies" and requires a "name", other tools should feel free to use package.json to store metadata.</p>

<p>A tool-specific name in the package.json can be used to encapsulate info that is only appropriate for that tool,or while that tool is working out a common config format that later could be used by multiple tools. For instance, volo will look in a "volo" property to find volo-specific configuration details.</p>

<p>This should be favored over creating separate .json files. Bower does this with component.json. This adds clutter. The nature of JSON key-based storage means that tool-specific info can be stored under unique keys in the package.json. Bower could use a "component" property in the package.json instead.</p>

<p>One thing I wish npm did differently was to not place so much dependence on the "name" field in the package.json.</p>

<p>Packages naming themselves have the same problems as modules naming themselves. The name should really be specified by the context consuming the package or module.</p>

<p>A package could have a very different name depending on the package repo or context it is used. For example, the requirejs "text" module is a loader plugin. Claiming the "text" name would be bad to do in a general package repository. However, in the context of a loader plugin it makes more sense. If a repository holds JS packages that can be used for multiple contexts, like browser and Node, a single name specified by the package is too limiting and often misleading.</p>

<p>One way to solve that is to store modules for a different contexts (like browser vs Node, in different package repositories. Even then, the same package could be useful in both, but need different names in each repository.</p>

<p>Another approach is to allow a larger namespace in a package repo. Volo does this by using GitHub as the repo, and GitHub has a two level namespace: "owner/repo", and the name of the repo is something specified outside of the package metadata.</p>

<h2 id="alternatives">Alternatives</h2>

<p>Some approaches that may mitigate the need for the four main points discussed above:</p>

<h3 id="everythinginadirectory">Everything in a directory</h3>

<p>Do not allow single JS files, and work out a convention that is based on each dependency in a directory.</p>

<p>This does not carry over well once you start coding application logic, where you have multiple single purpose modules that favor the single JS file approach for each module ID. It also creates a bunch of extra noise in a project, and feels too much like Java.</p>

<p>This approach works in Node because it can do multiple IO lookup operations for a module ID. This does not work well for the browser case.</p>

<h3 id="buildeverything">Build everything</h3>

<p>Who cares about file debris and big configuration blocks, mandate builds to clean up the mess for browsers!</p>

<p>This is not how front end projects have worked in the past. There is great simplicity, immediacy, and "view source" value in being able to just code some static files and load them directly in the browser.</p>

<p>I cannot see any future module system in ECMAScript mandating builds just to use modules in the browser. We need to figure out an approach that works without needing build tools.</p>

<p>Making sure a system can work without build tools helps nudge people to simpler libraries and project layouts. Once build tools become involved, it means more levels to debug and more things to set up before getting started. It leads down the path to Java and <a href="http://en.wikipedia.org/wiki/List_of_web_service_specifications">WS-Deathstar</a>. Keep the web simpler.</p>

<p>Build tools are great if you want to squeeze out every last bit of performance, but they should be optional. Many folks run AMD projects without building, and they are fine with the performance.</p>

<p>Build tools are also useful when trying to work out how something should work in the future, like CSS. CSS has been so neglected over the years that using LESS or SASS-like systems is alluring. Hopefully those are just intermediate efforts to better inform improvements in CSS, so that they eventually become built in to CSS itself.</p>

<p>If not, hopefully module systems support loader plugins so that these CSS builders can run in the browser without needing builds.</p>

<h2 id="summary">Summary</h2>

<p>The above approach as been demonstrated to work, and it is in active use. While the "everything is a directory" and "build everything" do not seem like viable long range solutions, it would be great to hear of other solutions that work well in practice.</p>]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Understanding macro use cases for JavaScript]]></title>
        <link href="https://jrburke.com/2012/09/15/understanding-macro-use-cases-for-javascript/"/>
        <updated>2012-09-15T21:56:22.032Z</updated>
        <id>https://jrburke.com/2012/09/15/understanding-macro-use-cases-for-javascript/</id>
        <content type="html"><![CDATA[<p>I just watched <a href="https://air.mozilla.org/sweetjs/">this Mozilla video on some experimental work Tim Disney is doing
for JS macros</a>. While
watching it, I also read came across <a href="http://calculist.org/blog/2012/04/17/homoiconicity-isnt-the-point/">Dave Herman's homoiconicity post</a>.</p>

<p>Interesting stuff, and helped me to better understand how macros might fit
into JavaScript, at least at a technical level.</p>

<p>My crude layman's explanation of macros: transpilers but only JS token
types are used, versus having to make your own whole grammar, and constrained to <strike>curlies</strike>
() {} [] as delimiters (thanks to Tim for the correction). These limitations are there in order to insert in a simplified
parser (called the reader) between the usual JS lexer and parser stages.</p>

<p>So macros seem to be useful when:</p>

<ul>
<li>you do not want a full transpiler, just some small syntax forms</li>
<li>and using a function() to do the code reuse is not appropriate</li>
</ul>

<p>I am having trouble visualizing those use cases though. My initial reaction is
that macros are something neat for a language enthusiast, but do not actually
make coding, the sharing and reading of code, that much better, particularly
since it involves a level of indirection that is subtle, the new grammar needs
to be tracked down. I find this is the hardest part of understanding codebases,
tracking down what different units of code are doing, where the definitions live.</p>

<p>My first impulse is to say, "just make a function" that does
what you want, using existing JS grammar.</p>

<p>If a function is not enough, what you are probably wanting is a full custom
language, so then a full grammar/transpiler makes sense.
The use of transpilers are easier to call out in their use -- normally a different
file extension, and by not being limited to JS token types/delimiters, you are
more likely to create a terser grammar.</p>

<p>I can see the need to make transpiler construction easier. And if someone wanted
to create a "like JS but with some tweaks", maybe create something higher
level than something like <a href="http://zaach.github.com/jison/">jison</a> to do that.
I would have liked that when playing around with module syntax for JS, for
example.</p>

<p>So it is hard for me to see the case for macros, at least as described in
that video. They seem to be a middle ground between functions and full
transpilers whose benefits seem to be outweighed by making it more difficult
to comprehend code written in "JavaScript".</p>

<p>But I am trying to learn more about it. If anyone has pointers to the cases
where macros shine and their use outweighs my perceived readability/code tracing
costs, I would love to hear it. Feel free to leave a comment.</p>

<p>However, do not comment with at "yeah macros are dumb". This is an exploration
in enlightenment. I'm already skeptical of macros, so I do not need that
reinforcement. I'm looking for more concrete use cases, pros and cons on specific
points, not fear of change.</p>

<p>Similarly, comments of the form "because, Language X has them and
they are awesome" will likely not be informative. It is likely language X and
JS do not share other properties and cultures that are in JS, like the
propensity to create transpilers for JS. I want uses cases that for JS would not
be solved via functions or a full transpiler.</p>]]></content>
    </entry>

</feed>
